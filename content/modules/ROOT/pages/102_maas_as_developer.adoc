= Lab Exercise: Using MaaS as a Developer
:stem: latexmath
:icons: font
:toc: left
:source-highlighter: highlight.js
:numbered:

This exercise will guide you through the process of deploying AnythingLLM as a custom workbench in OpenShift AI and configuring it to connect to a Large Language Model (LLM) that is being served via a Model-as-a-Service (MaaS) pattern with 3scale managing API access.

== *Finish configuring 3Scale developer portal*

[IMPORTANT]
====
3Scale API Gateway has been provisioned by the AI-Accelerator-Example bootstrapped in last section. For the developer portal to be available to developers, the Administrator needs to remove a lock used to prevent developers access while making customizations. This lock is an access code that once removed will allow the developers access.
====

To get this done do the following:

. Get the 3Scale Admin user and password:
+
[.console-input]
[source,bash]
oc get secret system-seed -n 3scale -o template='{{range $key, $value := .data}}{{if or (eq $key "ADMIN_USER") (eq $key "ADMIN_PASSWORD")}}{{printf "%s: " $key}}{{ $value | base64decode }}{{"\n"}}{{end}}{{end}}'

. Open the Admin URL in a browser:
+
[.console-input]
[source,bash]
oc get routes -n 3scale -o json | jq -r '.items[] | select(.spec.host | contains("maas-admin")) | "https://"+.spec.host'

. Once you enter the credentials, dismiss the wizard by clicking the top right X icon.

. Navigate to Dashboard -> Audience -> Developer Portal -> Settings -> Domains & Access
+
image::102_maas_as_developer_02.png[audience, 200]  
+
image::102_maas_as_developer_03.png[access, 300] 

. Delete the 'Developer Portal Access Code' and click Update Account
+
image::102_maas_as_developer_04.png[update, 300] 

. Now get the URL for the developer portal and try to access it:
.. URL
+
[.console-input]
[source,bash]
oc get routes -n 3scale -o json | jq -r '.items[] | select(.spec.host | startswith("maas.apps")) | "https://"+.spec.host'

.. Click sign in and toggle the "Private login" and access with username: *dev1*, password: *openshift*
+
image::102_maas_as_developer_05.png[login,500] 

.. Model Name





Get model endpoint served by 3Scale:

[.console-input]
[source,bash]
----
oc get routes -n 3scale -o json | jq -r '.items[] | select(.spec.host | contains("llama-32-1b-instruct-cpu-maas-apicast-production")) | .spec.host'
----

Example:
https://llama-32-1b-instruct-cpu-maas-apicast-production.apps.cluster-hbp92.hbp92.sandbox1781.opentlc.com/v1




== *Ensure Model is Served via MaaS (3scale) and Obtain API Key*

*Objective*: Before you can configure AnythingLLM, you need to ensure that the LLM you wish to use is accessible through a Model-as-a-Service (MaaS) setup, specifically one that leverages 3scale for API management. You will also obtain the necessary connection details.


1. Understand MaaS and 3scale's Role:
    * Model-as-a-Service (MaaS) is the architectural pattern we explained before.
    * 3scale acts as the primary entry point for users to quickly access AI models within the MaaS solution. It is a versatile component that authorizes and reports traffic to the model serving layer on OpenShift AI.
2. Obtain API Key and Endpoint Details:
    * Log in to the MaaS Platform (powered by 3scale): After logging into the MaaS platform, users can create a new application.
    * Select the Desired AI Model: Choose the specific AI model you are interested in using.
    * Retrieve Connection Details: The platform will instantly provide you with the necessary connection details. These include:
        ▪ Endpoint URL
        ▪ Model Name
        ▪ A unique API Key, which functions as an api_key parameter or an Authorization Bearer token for your API calls.
    * Record these details carefully, as you will need them for configuring AnythingLLM.

== Step 3: Create and launch the AnythingLLM Workbench

*Objective*: You will create a new workbench with AnythingLLM image.

. Access Openshift AI
. Navigate to the Data Science Projects and open the ```LLM Host``` project 
. Click the create workbench 

. Configure Workbench Details:
    * Name: Choose a descriptive name, such as "anythingllm-wb".
    * Image selection: Select the pre-loaded "CUSTOM-AnythingLLM".
    * For version select ```1.3.0```.
    * For Hardware Profile: Choose Small (a GPU is not required for this since is just a web server).
    * Leave the remaining settings as default and click Create.

+
- Custom workbench using AnythingLLM:
+
image::102_maas_as_developer_01.png[] 

. Next, wait for the workbench to start, this starts a process to retrieve the image and run the pod.
+
image::102_maas_as_developer_04.png[] 

. When available press the workbench image to open the URL in a separate browser tab and enter ```kubeadmin``` credentials to login:
+
image::102_maas_as_developer_05.png[] 

== Step 4: Configure the LLM Endpoint within AnythingLLM

*Objective*: This is the critical step where you connect your AnythingLLM workbench to the LLM model served by 3scale, using the API key and endpoint details obtained in Step 1.

1. Choose Provider: In the AnythingLLM configuration interface, select Generic OpenAI as the Provider from the available options.
2. Enter Base URL: Enter the Endpoint URL you obtained from 3scale as the Base URL. This URL should typically end with /v1 (e.g., https://mistral-7b-instruct-v0-3-mycluster.com:443/v1).
3. Enter API Key and Model Name: Enter the API Key and specify the Model Name that you received from 3scale.
4. Set Token Context Window and Max Tokens: Set the Token Context Window size and Max Tokens to be generated by default. A good starting point is 1024, and you can adjust this value later within your workspaces.


== Step 5: Final Setup and Interaction

*Objective*: Complete the AnythingLLM setup and begin using your private chatbot powered by the 3scale-served LLM.

1. Set Up User Access: On the next screen, select Just me. OpenShift's authentication already secures access to your workbench, so a secondary password is not typically necessary.
2. Review Configuration: Review the summary screen to confirm that all your settings are correct. You may skip any brief survey if prompted.
3. Create Workspace: Click on Create Workspace. This will set up a project area within AnythingLLM where you can organize different tasks and data.
4. Start Chatting: Navigate to your newly created workspace and begin interacting with the LLM. You can now explore the various features of AnythingLLM.


image::102_maas_as_developer_06.png[] 
image::102_maas_as_developer_07.png[] 
image::102_maas_as_developer_08.png[] 